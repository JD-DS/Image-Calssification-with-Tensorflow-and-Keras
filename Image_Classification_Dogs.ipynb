{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88ea0a3f-d9cd-4bd3-8042-a4083fd45439",
   "metadata": {},
   "source": [
    "# Classifying Dog Images with Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8cf8d-b192-488c-a8b2-b035f89192d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and packages needed for image classification project\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea75ad-4208-4aa1-87e2-c128d45145ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the breed of dogs that the program will be classifying \n",
    "\n",
    "breeds = ['beagle','bernese_mountain_dog','doberman','labrador_retriever','siberian_husky']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899aa2de-70cb-4374-a51a-fee00021e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the arguments for the tensorflow instance\n",
    "args = {\n",
    "    'labels':'inferred',          # Infers the name of the dog by the name of the directory the picture is in\n",
    "    'label_mode':'categorical',   # Each breed is one category\n",
    "    'batch_size': 32,             # how many images are loaded and processed at once by neural network\n",
    "    'image_size': (256,256),      # resize all images to the same size \n",
    "    'seed': 1,                    # set seed for reproducability\n",
    "    'validation_split': .2,       # split training and testing : 80% train and 20% test\n",
    "    'class_names': breeds         # name of the categories\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cabd7e9-5467-474b-98cc-f97d21686dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data \n",
    "\n",
    "train = tf.keras.utils.image_dataset_from_directory(           # Loads images from directory into tensorflow training dataset\n",
    "    'images',\n",
    "    subset='training',\n",
    "    **args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb28527-fc14-44c9-9786-f06e0f3c826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "\n",
    "test = tf.keras.utils.image_dataset_from_directory(           # Loads images from directory into tensorflow  testing dataset\n",
    "    'images',\n",
    "    subset='validation',\n",
    "    **args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba81d58-9bd5-4c98-81b5-12b6fd445c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train  # Can se that this is a batch dataset, a.k.a batch is a tensorlfow class that represents data loaded into tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a009505a-31e5-4678-8164-7d76803b69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = train.take(1)   # Saves the first batch of images to a variable 'first'... from above: 1 batch = 32 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33075be-2767-4e1d-bf69-257efc74dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two new variables images, which will hold the first 32 images and labels, which will hold the labels of the first 32 images\n",
    "\n",
    "images, labels = list(first)[0]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679e052-e672-42f7-a07d-9b738d405ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the first image in the batch \n",
    "\n",
    "first_image = images[1]\n",
    "#first_image                # saved as a numpy array that holds matrices of numbers coresponding to pixels and RGB content in the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b213a1-f5a5-460b-be93-b12cb83289d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert above numpy arrays into the image using Pillow library\n",
    "\n",
    "from PIL import Image\n",
    "Image.fromarray(first_image.numpy().astype('uint8'))   # Pillow converts numpy matrices into the image itslef \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b94f83-06de-4422-9442-b88f0bb397bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]   # numpy array shows binary inputs that tell us which kind of dog it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e4799-dd17-4a40-bc7e-ace4f0de125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.cache().prefetch(buffer_size=tf.data.AUTOTUNE)   # Caches pictures in memory rather than hard disk to make algorithm more efficient\n",
    "test = test.cache().prefetch(buffer_size=tf.data.AUTOTUNE)   # Caches pictures in memory rather than hard disk to make algorithm more efficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9fe96-9320-4fd3-93af-efc6a87c4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras packages for modeling and build sequential model\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential ([\n",
    "    layers.Rescaling(1./255),    # Pixels in numpy array are from 0 - 255, so we rescale the pixels into numbers between 0-1 in order to help neural network be more efficient\n",
    "    layers.Conv2D(16,3,padding='same',activation='relu',input_shape=(256,256,3)),             # Create a convulutional layer that scans images and generates new matrices with features from the images, will do this 16 times, looking at 3x3 pixels nat a time(window)\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128,activation='relu'),  # dense network will take flattened layer and help facilitate predictions\n",
    "    layers.Dense(len(breeds))             # this line will make the prediction\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd872d2-5c66-4484-baa9-df977cfa4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics =['accuracy'])     # optimizer tells model how to predict error and how to iterate, and loss function calculates error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a32de-d824-4296-b8b2-e54380ece3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=test,\n",
    "    epochs=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e404c-7284-4fe6-8daf-348e7ae40ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the model and its layers / how they are working\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Rescaling layer output the images and rescaled them\n",
    "# Convulutional layer created 16 matrices of image features\n",
    "# flattening layer flatened matrices into one lon vector\n",
    "# Dense layer took that vector and use dit to make prediction\n",
    "# Dense_3 seperated a single vector for each image indicating which class it belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f380f-250e-44c2-92ef-3df23e29fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph model accuracy with pandas\n",
    "import pandas as pd\n",
    "\n",
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "history_df[['accuracy','val_accuracy']].plot();\n",
    "\n",
    "# Training accuracy went up but validation accuracy did not\n",
    "# model may be overfit - random features are being implemented by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf112ace-a643-4abf-b4ea-c242fc8c4658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account for overfitting and increas emodel accuracy\n",
    "# paste model from before into function so as to not have to change the code every time\n",
    "\n",
    "def train_model(network,epochs=5):\n",
    "    model = Sequential(network)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics =['accuracy'])\n",
    "    history = model.fit(\n",
    "    train,\n",
    "    validation_data=test,\n",
    "    epochs=5,\n",
    "    verbose=1\n",
    ")\n",
    "    history_df = pd.DataFrame.from_dict(history.history)\n",
    "    return history_df,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84399c71-2e87-419f-b000-4de2179a40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same netwrok as before, modified with new layers\n",
    "\n",
    "network = [\n",
    "    layers.Rescaling(1./255),    \n",
    "    layers.Conv2D(16,4,padding='same',activation='relu',input_shape=(256,256,3)),     # increase window size to 4 from 3\n",
    "    layers.MaxPooling2D(),                                                            # add max pooling 2d layer to reduce overfit and reduce number of parameters\n",
    "    layers.Conv2D(32,4,padding='same',activation='relu',input_shape=(256,256,3)),     # add second convolutional layer with increased filters to 32, to let network pick up higher level features\n",
    "    layers.MaxPooling2D(),                                                           # add another max pooling layer\n",
    "    layers.Conv2D(64,4,padding='same',activation='relu',input_shape=(256,256,3)),    # add another convolutional layer with 64 filters for even higher level features\n",
    "    layers.MaxPooling2D(),                                                           # another max pooling layer\n",
    "    layers.Dropout(.2),                                                              # Dropout layer helps with overfitting by setting some outputs to 0 randomly, so network doesnt become too linked to trainjing data\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128,activation='relu'),  \n",
    "    layers.Dense(len(breeds))             \n",
    "]\n",
    "\n",
    "# run model again\n",
    "\n",
    "history_df,model = train_model(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133e25c-6058-4a44-9f21-51d52c89db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df[['accuracy','val_accuracy']].plot();  # not much of an accuracy increase: increase epochs and see changes\n",
    "\n",
    "# Still overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a7d35-a3f4-4441-a2ab-4214634b9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentaion may help with overfitting with keras layers, set to a sequential layer\n",
    "# set seeds for reproducibility \n",
    "\n",
    "data_augmentaion = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal',seed=1),         # Randomly flips images from left to right which the model wuill see as a new image and increase accuracy\n",
    "    layers.RandomRotation(.2,seed=1),               # Randomly raotates images for more information\n",
    "    layers.RandomZoom(.2,seed=1)                   #randomly zooms images for more information for the model \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb202cf-8341-4912-8f0a-a9ff62c5d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add netwroks together to create full network\n",
    "\n",
    "full_network = [data_augmentaion] + network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507c225-8a39-4121-a359-b79539f76651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the full network\n",
    "\n",
    "history_df, model = train_model(full_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65cf428-e4ba-4521-ac24-62718772c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy again\n",
    "\n",
    "history_df[['accuracy','val_accuracy']].plot();\n",
    "\n",
    "# Accuracy is much better now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93760343-2a67-4ede-81ee-c229aa4d44b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull predictions out and visulaize them \n",
    "\n",
    "preds = model.predict(test)    # large numpy array; convert to pandas dataframe to make it easier to work with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91755fad-2dd3-4c5c-accd-dbf9bbaeaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "predicted_class = np.argmax(preds,axis=1)    # turns predictions into a single number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843c118-24fb-4435-b6a6-03f895fca5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array of index of original breeds \n",
    "\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac021a-c4ff-415d-848b-3cabfee201d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = np.concatenate([y for x,y in test],axis=0)   # flattens out batches and pulls out labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce7590-ffcb-4796-bdfe-11b6c01f7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels   # they are vectors so change them to single numbers\n",
    "actual_class = np.argmax(actual_labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b607a-f0ba-4fb8-ac1d-f16b3d08b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual images of the dogs\n",
    "\n",
    "import itertools\n",
    "\n",
    "actual_image = [x.numpy().astype('uint8') for x,y in test]\n",
    "actual_image = list(itertools.chain.from_iterable(actual_image))\n",
    "actual_image = [Image.fromarray(a) for a in actual_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0a67d-c54c-42fd-ab2d-472a79c9404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datframe from predicted, actual, and the images of the dogs\n",
    "\n",
    "pred_df = pd.DataFrame(zip(predicted_class,actual_class,actual_image),columns=['prediction','actual','image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c0c48-ff28-46a9-980e-44a92ceceb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dog breeds from numbers to the actual names\n",
    "\n",
    "pred_df['prediction'] = pred_df['prediction'].apply(lambda x : breeds[x])\n",
    "pred_df['actual'] = pred_df['actual'].apply(lambda x : breeds[x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531fbc80-8ea5-428b-a234-56584c578495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disply Head of dataframe\n",
    "\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791c1e5-da3f-47dd-b4e8-9a735dff7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render actal images instead of image data\n",
    "\n",
    "import base64\n",
    "import io\n",
    "def image(img):\n",
    "    with io.BytesIO() as buffer:\n",
    "        img.save(buffer,'png')\n",
    "        img_str = base64.b64encode(buffer.getvalue()).decode()\n",
    "        return f'<img src=\"data:image/jpeg;base64,{img_str}\">'\n",
    "  \n",
    "    \n",
    "# this is all a little convoluted and had to look up how to do all of this, working with images and HTML\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedfc7bb-7ff3-464d-a155-7cd459461315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at predictions and acrtual dogs\n",
    "\n",
    "  \n",
    "pred_df.head(10).style.format({'image':image})\n",
    "\n",
    "# Labs and dobermans seem hard for the model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef5ebd-0875-41ef-88df-afbf9babd73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
